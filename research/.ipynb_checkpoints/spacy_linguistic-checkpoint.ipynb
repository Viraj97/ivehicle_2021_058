{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"spacy_linguistic-checkpoint.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"RBofb13UsrXs","executionInfo":{"status":"ok","timestamp":1633282530812,"user_tz":-330,"elapsed":2073,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}}},"source":["import spacy\n","nlp = spacy.load('en_core_web_sm')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7jebeFssrX8","executionInfo":{"status":"ok","timestamp":1633282530821,"user_tz":-330,"elapsed":32,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}}},"source":["doc = nlp(\"I am looking forward to have a dinner with Saurav today.\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4X8sguEsrX_","executionInfo":{"status":"ok","timestamp":1633282530823,"user_tz":-330,"elapsed":30,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}},"outputId":"9a6deb59-13e7-433e-db73-197670bb0090"},"source":["for token in doc:\n","    print(token.text + ' - ' + token.dep_)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["I - nsubj\n","am - aux\n","looking - ROOT\n","forward - advmod\n","to - aux\n","have - advcl\n","a - det\n","dinner - dobj\n","with - prep\n","Saurav - pobj\n","today - npadvmod\n",". - punct\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VII5Q9WksrYD","executionInfo":{"status":"ok","timestamp":1633282530825,"user_tz":-330,"elapsed":24,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}},"outputId":"fc81056e-4fd7-432b-b3c6-5a7ed268eaf0"},"source":["for token in doc:\n","    print(token.text, token.dep_, token.head.text, token.head.pos_,\n","          [child for child in token.children])"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["I nsubj looking VERB []\n","am aux looking VERB []\n","looking ROOT looking VERB [I, am, forward, have, .]\n","forward advmod looking VERB []\n","to aux have AUX []\n","have advcl looking VERB [to, dinner, with, today]\n","a det dinner NOUN []\n","dinner dobj have AUX [a]\n","with prep have AUX [Saurav]\n","Saurav pobj with ADP []\n","today npadvmod have AUX []\n",". punct looking VERB []\n"]}]},{"cell_type":"code","metadata":{"id":"kUAah1g-srYG","executionInfo":{"status":"ok","timestamp":1633282532704,"user_tz":-330,"elapsed":1896,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}}},"source":["import keras"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":766},"id":"F9e4bYmUsrYI","executionInfo":{"status":"error","timestamp":1633282554173,"user_tz":-330,"elapsed":21485,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}},"outputId":"cc131187-4898-4d0f-86ab-1c90ea93c83f"},"source":["# -*- coding: utf-8 -*-\n","'''An implementation of sequence to sequence learning for performing addition\n","\n","Input: \"535+61\"\n","Output: \"596\"\n","Padding is handled by using a repeated sentinel character (space)\n","\n","Input may optionally be reversed, shown to increase performance in many tasks in:\n","\"Learning to Execute\"\n","http://arxiv.org/abs/1410.4615\n","and\n","\"Sequence to Sequence Learning with Neural Networks\"\n","http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n","Theoretically it introduces shorter term dependencies between source and target.\n","\n","Two digits reversed:\n","+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n","\n","Three digits reversed:\n","+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n","\n","Four digits reversed:\n","+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n","\n","Five digits reversed:\n","+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n","'''\n","\n","from __future__ import print_function\n","from keras.models import Sequential\n","from keras import layers\n","import numpy as np\n","from six.moves import range\n","\n","\n","class CharacterTable(object):\n","    \"\"\"Given a set of characters:\n","    + Encode them to a one hot integer representation\n","    + Decode the one hot integer representation to their character output\n","    + Decode a vector of probabilities to their character output\n","    \"\"\"\n","    def __init__(self, chars):\n","        \"\"\"Initialize character table.\n","\n","        # Arguments\n","            chars: Characters that can appear in the input.\n","        \"\"\"\n","        self.chars = sorted(set(chars))\n","        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n","        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n","\n","    def encode(self, C, num_rows):\n","        \"\"\"One hot encode given string C.\n","\n","        # Arguments\n","            num_rows: Number of rows in the returned one hot encoding. This is\n","                used to keep the # of rows for each data the same.\n","        \"\"\"\n","        x = np.zeros((num_rows, len(self.chars)))\n","        for i, c in enumerate(C):\n","            x[i, self.char_indices[c]] = 1\n","        return x\n","\n","    def decode(self, x, calc_argmax=True):\n","        if calc_argmax:\n","            x = x.argmax(axis=-1)\n","        return ''.join(self.indices_char[x] for x in x)\n","\n","\n","class colors:\n","    ok = '\\033[92m'\n","    fail = '\\033[91m'\n","    close = '\\033[0m'\n","\n","# Parameters for the model and dataset.\n","TRAINING_SIZE = 50000\n","DIGITS = 3\n","REVERSE = True\n","\n","# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n","# int is DIGITS.\n","MAXLEN = DIGITS + 1 + DIGITS\n","\n","# All the numbers, plus sign and space for padding.\n","chars = '0123456789+ '\n","ctable = CharacterTable(chars)\n","\n","questions = []\n","expected = []\n","seen = set()\n","print('Generating data...')\n","while len(questions) < TRAINING_SIZE:\n","    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n","                    for i in range(np.random.randint(1, DIGITS + 1))))\n","    a, b = f(), f()\n","    # Skip any addition questions we've already seen\n","    # Also skip any such that x+Y == Y+x (hence the sorting).\n","    key = tuple(sorted((a, b)))\n","    if key in seen:\n","        continue\n","    seen.add(key)\n","    # Pad the data with spaces such that it is always MAXLEN.\n","    q = '{}+{}'.format(a, b)\n","    query = q + ' ' * (MAXLEN - len(q))\n","    ans = str(a + b)\n","    # Answers can be of maximum size DIGITS + 1.\n","    ans += ' ' * (DIGITS + 1 - len(ans))\n","    if REVERSE:\n","        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n","        # space used for padding.)\n","        query = query[::-1]\n","    questions.append(query)\n","    expected.append(ans)\n","print('Total addition questions:', len(questions))\n","\n","print('Vectorization...')\n","x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n","y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(questions):\n","    x[i] = ctable.encode(sentence, MAXLEN)\n","for i, sentence in enumerate(expected):\n","    y[i] = ctable.encode(sentence, DIGITS + 1)\n","\n","# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n","# digits.\n","indices = np.arange(len(y))\n","np.random.shuffle(indices)\n","x = x[indices]\n","y = y[indices]\n","\n","# Explicitly set apart 10% for validation data that we never train over.\n","split_at = len(x) - len(x) // 10\n","(x_train, x_val) = x[:split_at], x[split_at:]\n","(y_train, y_val) = y[:split_at], y[split_at:]\n","\n","print('Training Data:')\n","print(x_train.shape)\n","print(y_train.shape)\n","\n","print('Validation Data:')\n","print(x_val.shape)\n","print(y_val.shape)\n","\n","# Try replacing GRU, or SimpleRNN.\n","RNN = layers.LSTM\n","HIDDEN_SIZE = 128\n","BATCH_SIZE = 128\n","LAYERS = 1\n","\n","print('Build model...')\n","model = Sequential()\n","# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n","# Note: In a situation where your input sequences have a variable length,\n","# use input_shape=(None, num_feature).\n","model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n","# As the decoder RNN's input, repeatedly provide with the last hidden state of\n","# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n","# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n","model.add(layers.RepeatVector(DIGITS + 1))\n","# The decoder RNN could be multiple layers stacked or a single layer.\n","for _ in range(LAYERS):\n","    # By setting return_sequences to True, return not only the last output but\n","    # all the outputs so far in the form of (num_samples, timesteps,\n","    # output_dim). This is necessary as TimeDistributed in the below expects\n","    # the first dimension to be the timesteps.\n","    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n","\n","# Apply a dense layer to the every temporal slice of an input. For each of step\n","# of the output sequence, decide which character should be chosen.\n","model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n","model.add(layers.Activation('softmax'))\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","model.summary()\n","\n","# Train the model each generation and show predictions against the validation\n","# dataset.\n","for iteration in range(1, 10):\n","    print()\n","    print('-' * 50)\n","    print('Iteration', iteration)\n","    model.fit(x_train, y_train,\n","              batch_size=BATCH_SIZE,\n","              epochs=1,\n","              validation_data=(x_val, y_val))\n","    # Select 10 samples from the validation set at random so we can visualize\n","    # errors.\n","    for i in range(10):\n","        ind = np.random.randint(0, len(x_val))\n","        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n","        preds = model.predict_classes(rowx, verbose=0)\n","        q = ctable.decode(rowx[0])\n","        correct = ctable.decode(rowy[0])\n","        guess = ctable.decode(preds[0], calc_argmax=False)\n","        print('Q', q[::-1] if REVERSE else q, end=' ')\n","        print('T', correct, end=' ')\n","        if correct == guess:\n","            print(colors.ok + '☑' + colors.close, end=' ')\n","        else:\n","            print(colors.fail + '☒' + colors.close, end=' ')\n","        print(guess)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating data...\n","Total addition questions: 50000\n","Vectorization...\n","Training Data:\n","(45000, 7, 12)\n","(45000, 4, 12)\n","Validation Data:\n","(5000, 7, 12)\n","(5000, 4, 12)\n","Build model...\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 128)               72192     \n","_________________________________________________________________\n","repeat_vector (RepeatVector) (None, 4, 128)            0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 4, 128)            131584    \n","_________________________________________________________________\n","time_distributed (TimeDistri (None, 4, 12)             1548      \n","_________________________________________________________________\n","activation (Activation)      (None, 4, 12)             0         \n","=================================================================\n","Total params: 205,324\n","Trainable params: 205,324\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n","--------------------------------------------------\n","Iteration 1\n","352/352 [==============================] - 13s 30ms/step - loss: 1.8814 - accuracy: 0.3241 - val_loss: 1.7978 - val_accuracy: 0.3358\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-efdf8aa7f09e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mrowx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"]}]},{"cell_type":"code","metadata":{"id":"KXdAHHQ6BCmB","executionInfo":{"status":"aborted","timestamp":1633282554149,"user_tz":-330,"elapsed":36,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}}},"source":["!pip install keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ojfzm8SOBT7U","executionInfo":{"status":"aborted","timestamp":1633282554154,"user_tz":-330,"elapsed":40,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}}},"source":["from tensorflow.keras.utils import to_categorical"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vPzDsb3usrYb","executionInfo":{"status":"aborted","timestamp":1633282554157,"user_tz":-330,"elapsed":43,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}}},"source":["from numpy import array\n","from keras.preprocessing.text import Tokenizer\n","#from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Embedding\n","\n","data = \"\"\" Jack and Jill went up the hill\\n\n","\t\tTo fetch a pail of water\\n\n","\t\tJack fell down and broke his crown\\n\n","\t\tAnd Jill came tumbling after\\n \"\"\"\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([data])\n","encoded = tokenizer.texts_to_sequences([data])[0]\n","print(encoded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ShLeUfHUsrYe","executionInfo":{"status":"aborted","timestamp":1633282554160,"user_tz":-330,"elapsed":45,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}}},"source":["vocab_size = len(tokenizer.word_index) + 1\n","print(vocab_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdodQSWRsrYg","executionInfo":{"status":"aborted","timestamp":1633282554164,"user_tz":-330,"elapsed":49,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}}},"source":["sequences = list()\n","for i in range(1, len(encoded)):\n","    sequence = encoded[i - 1 : i + 1]\n","    print(sequence)\n","    sequences.append(sequence)\n","\n","print(len(sequences))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yh3C_oxRsrYj","executionInfo":{"status":"aborted","timestamp":1633282554167,"user_tz":-330,"elapsed":52,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}}},"source":["sequences = array(sequences)\n","x, y = sequences[:, 0], sequences[:, 1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CkEOJgjasrYl","executionInfo":{"status":"aborted","timestamp":1633282554169,"user_tz":-330,"elapsed":50,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}}},"source":["y = to_categorical(y, num_classes=vocab_size)\n","print(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqiOu7pxsrYn","executionInfo":{"status":"aborted","timestamp":1633282554171,"user_tz":-330,"elapsed":51,"user":{"displayName":"Buddhini Maheshika","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01987419130217035841"}}},"source":["model = Sequential()\n","model.add(Embedding(vocab_size, 10, input_length=1))\n","model.add(LSTM(50))\n","model.add(Dense(vocab_size, activation='softmax'))"],"execution_count":null,"outputs":[]}]}