{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c80434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "#import spacy\n",
    "import string\n",
    "import gensim\n",
    "import operator\n",
    "import re\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ab819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('vehicle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b27804a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Buy/sell</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Color</th>\n",
       "      <th>Year</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>buy</td>\n",
       "      <td>brandnew</td>\n",
       "      <td>toyota</td>\n",
       "      <td>corolla</td>\n",
       "      <td>car</td>\n",
       "      <td>black</td>\n",
       "      <td>2008</td>\n",
       "      <td>buy    brandnew toyota corolla car black 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>buy</td>\n",
       "      <td>brandnew</td>\n",
       "      <td>bmw</td>\n",
       "      <td>x1</td>\n",
       "      <td>suv</td>\n",
       "      <td>white</td>\n",
       "      <td>2007</td>\n",
       "      <td>buy brandnew bmw x1 suv white 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>buy</td>\n",
       "      <td>recondition</td>\n",
       "      <td>benz</td>\n",
       "      <td>c200</td>\n",
       "      <td>car</td>\n",
       "      <td>green</td>\n",
       "      <td>2017</td>\n",
       "      <td>buy recondition benz c200 car green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>buy</td>\n",
       "      <td>brandnew</td>\n",
       "      <td>audi</td>\n",
       "      <td>a1</td>\n",
       "      <td>car</td>\n",
       "      <td>ash</td>\n",
       "      <td>2007</td>\n",
       "      <td>buy brandnew audi a1 car ash 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>sell</td>\n",
       "      <td>brandnew</td>\n",
       "      <td>bmw</td>\n",
       "      <td>x3</td>\n",
       "      <td>suv</td>\n",
       "      <td>black</td>\n",
       "      <td>2007</td>\n",
       "      <td>sell brandnew bmw x3 suv black 2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No Buy/sell    Condition   Brand    Model Type  Color  Year  \\\n",
       "0   1   buy        brandnew  toyota  corolla  car  black  2008   \n",
       "1   2      buy     brandnew     bmw       x1  suv  white  2007   \n",
       "2   3     buy   recondition    benz     c200  car  green  2017   \n",
       "3   4      buy     brandnew    audi       a1  car    ash  2007   \n",
       "4   5     sell     brandnew     bmw       x3  suv  black  2007   \n",
       "\n",
       "                                        Keywords  \n",
       "0  buy    brandnew toyota corolla car black 2008  \n",
       "1             buy brandnew bmw x1 suv white 2007  \n",
       "2            buy recondition benz c200 car green  \n",
       "3              buy brandnew audi a1 car ash 2007  \n",
       "4            sell brandnew bmw x3 suv black 2007  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab284b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy/sell => ['buy   ' 'buy' 'buy ' 'sell' 'sell   ' 'buy  ']\n",
      "Condition => ['brandnew' 'recondition']\n",
      "Brand => ['toyota' 'bmw' 'benz' 'audi']\n",
      "Model => ['corolla' 'x1' 'c200' 'a1' 'x3' 'x2' 'allion' 'c180' 'a3' 'yaris' 'KDH']\n",
      "Type => ['car' 'suv' 'van']\n",
      "Color => ['black' 'white' 'green' 'ash' 'red' 'blue']\n",
      "Keywords => ['buy    brandnew toyota corolla car black 2008'\n",
      " 'buy brandnew bmw x1 suv white 2007'\n",
      " 'buy recondition benz c200 car green' 'buy brandnew audi a1 car ash 2007'\n",
      " 'sell brandnew bmw x3 suv black 2007'\n",
      " 'buy    recondition bmw x2 suv red 2007'\n",
      " 'sell    recondition toyota allion car white 2007'\n",
      " 'sell brandnew benz c180 car ash 2014'\n",
      " 'buy brandnew audi a3 car black 2007'\n",
      " 'buy brandnew toyota yaris car red 2018'\n",
      " 'sell brandnew audi a1 car green 2007'\n",
      " 'sell    recondition benz c180 car black 2012'\n",
      " 'buy brandnew benz c200 car white 2007'\n",
      " 'buy   recondition audi a3 car green 2008'\n",
      " 'sell    recondition toyota corolla car red 2008'\n",
      " 'buy brandnew benz c180 car ash 2012'\n",
      " 'sell brandnew bmw x3 suv black 2014'\n",
      " 'buy   recondition audi a3 car white 2007'\n",
      " 'sell brandnew toyota yaris car red 2008'\n",
      " 'buy brandnew toyota corolla van black 2008'\n",
      " 'buy recondition benz c200 car green 2018'\n",
      " 'buy brandnew audi a1 car ash 2020'\n",
      " 'buy   recondition bmw x2 suv red 2007'\n",
      " 'sell recondition toyota allion car white 2007'\n",
      " 'sell brandnew benz c180 car ash 2018'\n",
      " 'buy brandnew toyota yaris car red 2019'\n",
      " 'buy recondition benz c180 car black 2018'\n",
      " 'buy recondition audi a3 car green 2011'\n",
      " 'sell recondition toyota corolla car red 2009'\n",
      " 'buy brandnew benz c180 car ash 2008'\n",
      " 'sell brandnew bmw x3 suv black 2008'\n",
      " 'buy recondition audi a3 car white 2017'\n",
      " 'buy brandnew toyota corolla car black 2012'\n",
      " 'buy recondition benz c200 car green 2008'\n",
      " 'buy brandnew audi a1 car ash 2013' 'buy recondition bmw x2 suv red 2007'\n",
      " 'sell brandnew benz c180 car ash 2021'\n",
      " 'buy recondition audi a3 car black 2012'\n",
      " 'buy brandnew toyota yaris car red 2008'\n",
      " 'sell brandnew audi a1 car green 2014'\n",
      " 'buy recondition benz c180 car black 2008'\n",
      " 'buy brandnew benz c200 car white 2016'\n",
      " 'buy recondition audi a3 car green 2008'\n",
      " 'sell recondition toyota corolla car red 2008'\n",
      " 'buy brandnew toyota corolla car black 2008'\n",
      " 'sell brandnew bmw x1 suv white 2020' 'buy brandnew audi a1 car ash 2021'\n",
      " 'sell brandnew bmw x3 suv black 2017'\n",
      " 'buy recondition bmw x2 suv red 2019'\n",
      " 'sell recondition toyota allion car white 2019'\n",
      " 'sell brandnew benz c180 car ash 2008'\n",
      " 'buy brandnew bmw x1 suv white 2015'\n",
      " 'buy brandnew benz c180 car ash 2016'\n",
      " 'buy recondition audi a3 car white 2015'\n",
      " 'buy brandnew toyota corolla car black 2020'\n",
      " 'buy brandnew bmw x1 suv white 2009'\n",
      " 'buy recondition benz c200 car green 2010'\n",
      " 'buy brandnew audi a1 car ash 2010' 'sell brandnew bmw x3 suv black 2011'\n",
      " 'buy recondition bmw x2 suv red 2013'\n",
      " 'sell recondition toyota allion car white 2015'\n",
      " 'sell brandnew benz c180 car ash 2010'\n",
      " 'buy brandnew audi a3 car black 2011'\n",
      " 'buy recondition audi a3 car white 2014'\n",
      " 'buy brandnew bmw x1 suv white 2019'\n",
      " 'sell brandnew bmw x3 suv black 2010'\n",
      " 'buy recondition bmw x2 suv red 2011'\n",
      " 'buy brandnew toyota yaris car red 2010'\n",
      " 'buy recondition benz c180 car black 2010'\n",
      " 'buy recondition audi a3 car white 2007'\n",
      " 'buy brandnew toyota KDH van black 2008'\n",
      " 'buy recondition bmw x2 suv red 2020'\n",
      " 'sell recondition toyota allion car white 2013'\n",
      " 'buy brandnew bmw x1 suv white 2018'\n",
      " 'buy brandnew audi a3 car black 2009'\n",
      " 'buy recondition benz c180 car black 2011'\n",
      " 'sell recondition toyota corolla car red 2019'\n",
      " 'buy brandnew audi a1 car ash 2017'\n",
      " 'buy brandnew toyota yaris car red 2009'\n",
      " 'buy recondition benz c180 car black 2009'\n",
      " 'sell brandnew bmw x3 suv black 2016'\n",
      " 'buy recondition bmw x2 suv red 2016'\n",
      " 'buy brandnew audi a3 car black 2019'\n",
      " 'buy brandnew benz c200 car white 2020'\n",
      " 'buy recondition audi a3 car white 2010'\n",
      " 'buy brandnew audi a1 car ash 2015' 'buy brandnew bmw x1 suv white 2010'\n",
      " 'buy brandnew audi a3 car black 2010'\n",
      " 'sell brandnew audi a1 car green 2017'\n",
      " 'buy brandnew benz c200 car white 2018'\n",
      " 'buy recondition audi a3 car white 2020'\n",
      " 'buy brandnew audi a1 car ash 2012' 'sell brandnew bmw x3 suv black 2012'\n",
      " 'buy recondition bmw x2 suv red 2012'\n",
      " 'sell recondition toyota allion car white 2012'\n",
      " 'buy brandnew audi a3 car black 2015'\n",
      " 'sell brandnew audi a1 car green 2013'\n",
      " 'buy brandnew benz c200 car white 2013'\n",
      " 'buy recondition audi a3 car white 2011'\n",
      " 'buy brandnew bmw x1 suv white 2011'\n",
      " 'sell brandnew bmw x3 suv black 2009'\n",
      " 'buy recondition bmw x2 suv red 2009'\n",
      " 'sell recondition toyota allion car white 2011'\n",
      " 'buy brandnew audi a3 car black 2008'\n",
      " 'sell recondition toyota allion car white 2014'\n",
      " 'buy brandnew benz c200 car white 2017'\n",
      " 'buy recondition bmw x2 suv red 2015'\n",
      " 'sell recondition toyota allion car white 2009'\n",
      " 'sell brandnew audi a1 car green 2019'\n",
      " 'buy brandnew benz c200 car white 2009'\n",
      " 'buy brandnew bmw x1 suv white 2014' 'buy brandnew audi a1 car ash 2014'\n",
      " 'sell brandnew bmw x3 suv black 2013'\n",
      " 'sell recondition toyota allion car white 2016'\n",
      " 'buy brandnew bmw x1 suv white 2008'\n",
      " 'buy brandnew audi a3 car black 2018'\n",
      " 'sell brandnew audi a1 car green 2020'\n",
      " 'buy recondition audi a3 car white 2012'\n",
      " 'buy brandnew bmw x1 suv white 2016' 'buy brandnew audi a1 car ash 2018'\n",
      " 'sell brandnew bmw x3 suv black 2018'\n",
      " 'buy brandnew benz c200 car white 2019'\n",
      " 'buy brandnew audi a1 car ash 2019' 'buy brandnew audi a3 car black 2014'\n",
      " 'sell brandnew benz c200 car white 2007'\n",
      " 'sell recondition audi a3 car green 2008'\n",
      " 'buy recondition bmw x2 suv red 2018'\n",
      " 'buy recondition audi a3 car black 2011'\n",
      " 'sell brandnew audi a1 car green 2011'\n",
      " 'buy brandnew benz c200 car white 2015'\n",
      " 'buy recondition audi a3 car white 2018'\n",
      " 'buy brandnew bmw x1 suv white 2020'\n",
      " 'buy recondition audi a3 car white 2009'\n",
      " 'sell brandnew bmw x1 suv white 2007'\n",
      " 'sell recondition toyota allion car white 2017'\n",
      " 'buy brandnew bmw x1 suv white 2017'\n",
      " 'buy recondition benz c200 car green 2016'\n",
      " 'sell brandnew benz c180 car ash 2013'\n",
      " 'buy brandnew toyota yaris car red 2016'\n",
      " 'buy recondition audi a3 car green 2019'\n",
      " 'sell recondition toyota corolla car red 2014'\n",
      " 'buy brandnew benz c180 car ash 2019'\n",
      " 'sell brandnew bmw x3 suv black 2020'\n",
      " 'sell brandnew toyota yaris car red 2018'\n",
      " 'buy brandnew toyota yaris car red 2013'\n",
      " 'sell recondition benz c180 car black 2016'\n",
      " 'sell recondition toyota KDH van blue 2019'\n",
      " 'buy brandnew audi a3 car white 2007'\n",
      " 'sell brandnew toyota yaris car red 2009']\n"
     ]
    }
   ],
   "source": [
    "#describe the unique values in categorical columns\n",
    "categorical_col = []\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == object:\n",
    "        categorical_col.append(col)\n",
    "        print(f\"{col} => {data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb602d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#handling categorical variable through label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_col:\n",
    "    data[col] = label_encoder.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb127f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Buy/sell</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Color</th>\n",
       "      <th>Year</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  Buy/sell  Condition  Brand  Model  Type  Color  Year  Keywords\n",
       "0   1         3          0      3      6     0      1  2008         0\n",
       "1   2         0          0      2      7     1      5  2007        39\n",
       "2   3         1          1      1      5     0      3  2017        83\n",
       "3   4         0          0      0      1     0      0  2007         5\n",
       "4   5         4          0      2      9     1      1  2007       117"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c02bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataset into dependent and independent variables\n",
    "X = data.drop(['No','Keywords'],axis=1)\n",
    "y = data.Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58e49e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   Buy/sell   500 non-null    int32\n",
      " 1   Condition  500 non-null    int32\n",
      " 2   Brand      500 non-null    int32\n",
      " 3   Model      500 non-null    int32\n",
      " 4   Type       500 non-null    int32\n",
      " 5   Color      500 non-null    int32\n",
      " 6   Year       500 non-null    int64\n",
      "dtypes: int32(6), int64(1)\n",
      "memory usage: 15.8 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2df4410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1     39\n",
       "2     83\n",
       "3      5\n",
       "4    117\n",
       "Name: Keywords, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c1bf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#split dataset for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)#,random_state=42)\n",
    "\n",
    "model= DecisionTreeClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test,predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e73b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('RFC', RandomForestClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858a72a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.627500 (0.042500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 553, in fit\n",
      "    self._solve_svd(X, y)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 478, in _solve_svd\n",
      "    _, S, Vt = linalg.svd(X, full_matrices=0)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\", line 121, in svd\n",
      "    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\lapack.py\", line 1007, in _compute_lwork\n",
      "    raise ValueError(\"Internal work array size computation failed: \"\n",
      "ValueError: Internal work array size computation failed: -10\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 553, in fit\n",
      "    self._solve_svd(X, y)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 478, in _solve_svd\n",
      "    _, S, Vt = linalg.svd(X, full_matrices=0)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\", line 121, in svd\n",
      "    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\lapack.py\", line 1007, in _compute_lwork\n",
      "    raise ValueError(\"Internal work array size computation failed: \"\n",
      "ValueError: Internal work array size computation failed: -10\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 553, in fit\n",
      "    self._solve_svd(X, y)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 478, in _solve_svd\n",
      "    _, S, Vt = linalg.svd(X, full_matrices=0)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\", line 121, in svd\n",
      "    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\lapack.py\", line 1007, in _compute_lwork\n",
      "    raise ValueError(\"Internal work array size computation failed: \"\n",
      "ValueError: Internal work array size computation failed: -10\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 553, in fit\n",
      "    self._solve_svd(X, y)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 478, in _solve_svd\n",
      "    _, S, Vt = linalg.svd(X, full_matrices=0)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\", line 121, in svd\n",
      "    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\lapack.py\", line 1007, in _compute_lwork\n",
      "    raise ValueError(\"Internal work array size computation failed: \"\n",
      "ValueError: Internal work array size computation failed: -10\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 553, in fit\n",
      "    self._solve_svd(X, y)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 478, in _solve_svd\n",
      "    _, S, Vt = linalg.svd(X, full_matrices=0)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\", line 121, in svd\n",
      "    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\lapack.py\", line 1007, in _compute_lwork\n",
      "    raise ValueError(\"Internal work array size computation failed: \"\n",
      "ValueError: Internal work array size computation failed: -10\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 553, in fit\n",
      "    self._solve_svd(X, y)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 478, in _solve_svd\n",
      "    _, S, Vt = linalg.svd(X, full_matrices=0)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\", line 121, in svd\n",
      "    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\lapack.py\", line 1007, in _compute_lwork\n",
      "    raise ValueError(\"Internal work array size computation failed: \"\n",
      "ValueError: Internal work array size computation failed: -10\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 553, in fit\n",
      "    self._solve_svd(X, y)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 478, in _solve_svd\n",
      "    _, S, Vt = linalg.svd(X, full_matrices=0)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\", line 121, in svd\n",
      "    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\lapack.py\", line 1007, in _compute_lwork\n",
      "    raise ValueError(\"Internal work array size computation failed: \"\n",
      "ValueError: Internal work array size computation failed: -10\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 553, in fit\n",
      "    self._solve_svd(X, y)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 478, in _solve_svd\n",
      "    _, S, Vt = linalg.svd(X, full_matrices=0)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\", line 121, in svd\n",
      "    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\lapack.py\", line 1007, in _compute_lwork\n",
      "    raise ValueError(\"Internal work array size computation failed: \"\n",
      "ValueError: Internal work array size computation failed: -10\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 553, in fit\n",
      "    self._solve_svd(X, y)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 478, in _solve_svd\n",
      "    _, S, Vt = linalg.svd(X, full_matrices=0)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\", line 121, in svd\n",
      "    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\lapack.py\", line 1007, in _compute_lwork\n",
      "    raise ValueError(\"Internal work array size computation failed: \"\n",
      "ValueError: Internal work array size computation failed: -10\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 553, in fit\n",
      "    self._solve_svd(X, y)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 478, in _solve_svd\n",
      "    _, S, Vt = linalg.svd(X, full_matrices=0)\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\", line 121, in svd\n",
      "    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],\n",
      "  File \"C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\scipy\\linalg\\lapack.py\", line 1007, in _compute_lwork\n",
      "    raise ValueError(\"Internal work array size computation failed: \"\n",
      "ValueError: Internal work array size computation failed: -10\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: nan (nan)\n",
      "KNN: 0.672500 (0.050559)\n",
      "CART: 0.810000 (0.043589)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.810000 (0.043589)\n",
      "SVM: 0.725000 (0.038730)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC: 0.810000 (0.043589)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\tcv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00a2cd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': LogisticRegression(),\n",
       " 'KNeighborsClassifier': KNeighborsClassifier(n_neighbors=2),\n",
       " 'SVC': SVC(random_state=42),\n",
       " 'DecisionTreeClassifier': DecisionTreeClassifier(random_state=10),\n",
       " 'RandomForestClassifier': RandomForestClassifier(n_estimators=60, random_state=0)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = ['LogisticRegression','KNeighborsClassifier','SVC','DecisionTreeClassifier','RandomForestClassifier']\n",
    "value = [LogisticRegression(), KNeighborsClassifier(n_neighbors=2, weights = 'uniform'),SVC(kernel = \"rbf\", random_state=42),DecisionTreeClassifier(random_state=10), RandomForestClassifier(n_estimators=60, random_state=0)]\n",
    "models = dict(zip(key,value))\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3d20192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.6\n",
      "KNeighborsClassifier 0.69\n",
      "SVC 0.1\n",
      "DecisionTreeClassifier 0.73\n",
      "RandomForestClassifier 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ushana\\anaconda3\\envs\\Semantic\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "predicted =[]\n",
    "for name, algo in models.items():\n",
    "    model=algo\n",
    "    model.fit(X_train, y_train)\n",
    "    predict = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, predict)\n",
    "    predicted.append(acc)\n",
    "    print(name,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3df13688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[0,0,2,7,1,5,2008]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71338d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading Gensim and nltk libraries\n",
    "'''\n",
    "# !pip install gensim\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3e58f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>want</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corolla</td>\n",
       "      <td>corolla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toyota</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bmw</td>\n",
       "      <td>bmw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>audi</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>benz</td>\n",
       "      <td>benz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sell</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KDH</td>\n",
       "      <td>kdh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2103</td>\n",
       "      <td>2103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>brandnew</td>\n",
       "      <td>brandnew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>recondition</td>\n",
       "      <td>recondit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>x1</td>\n",
       "      <td>x1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>c200</td>\n",
       "      <td>c200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>c180</td>\n",
       "      <td>c180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word   stemmed\n",
       "0           want      want\n",
       "1            buy       buy\n",
       "2        corolla   corolla\n",
       "3         toyota    toyota\n",
       "4            bmw       bmw\n",
       "5           audi      audi\n",
       "6           benz      benz\n",
       "7          black     black\n",
       "8          green     green\n",
       "9              i         i\n",
       "10          sell      sell\n",
       "11           KDH       kdh\n",
       "12          2008      2008\n",
       "13          2009      2009\n",
       "14          2007      2007\n",
       "15          2010      2010\n",
       "16          2011      2011\n",
       "17          2012      2012\n",
       "18          2103      2103\n",
       "19          2014      2014\n",
       "20          2015      2015\n",
       "21          2016      2016\n",
       "22          2017      2017\n",
       "23          2018      2018\n",
       "24          2019      2019\n",
       "25          2020      2020\n",
       "26          2021      2021\n",
       "27      brandnew  brandnew\n",
       "28   recondition  recondit\n",
       "29           red       red\n",
       "30         white     white\n",
       "31            x1        x1\n",
       "32          c200      c200\n",
       "33          c180      c180"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "original_words = ['want','buy','corolla','toyota','bmw','audi','benz','black','green','i','sell','KDH','2008','2009','2007','2010','2011','2012','2103','2014','2015','2016','2017','2018','2019','2020','2021','brandnew','recondition','red','white','x1','c200','c180']\n",
    "\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "\n",
    "pd.DataFrame(data={'original word':original_words, 'stemmed':singles })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e2b666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        \n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            \n",
    "            # TODO: Apply lemmatize_stemming() on the token, then add to the results list\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23e820ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to buy brandnew toyota corolla black car which made in 2008\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#win= tk.Tk()\n",
    "#Set the geometry of tkinter frame\n",
    "#ROOT.geometry(\"750x250\")\n",
    "ROOT = tk.Tk()\n",
    "\n",
    "ROOT.withdraw()\n",
    "# the input dialog\n",
    "USER_INP = simpledialog.askstring(title=\"Test\",\n",
    "                                  prompt=\"What you want?:\")\n",
    "\n",
    "# check it out\n",
    "print(USER_INP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98137f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'want', 'to', 'buy', 'brandnew', 'toyota', 'corolla', 'black', 'car', 'which', 'made', 'in', '2008']\n"
     ]
    }
   ],
   "source": [
    "sentence = USER_INP\n",
    "split_sentence = sentence.split(' ')\n",
    "print(split_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bc57b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "arr_Length=len(split_sentence)\n",
    "print(arr_Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e5ece38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '3', '6', '1', '0', '2008']\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "keywords=[]\n",
    "while i<arr_Length:\n",
    "    def buySell(x):\n",
    "        if x =='buy':\n",
    "            keywords.append(\"0\")\n",
    "        elif x =='sell':\n",
    "            keywords.append(\"1\")\n",
    "    def condition(x):\n",
    "        if x =='brandnew':\n",
    "            keywords.append(\"0\")\n",
    "        elif x =='recondition':\n",
    "            keywords.append(\"1\")\n",
    "    def brand(x):\n",
    "        if x =='toyota':\n",
    "            keywords.append(\"3\")\n",
    "        elif x =='bmw':\n",
    "            keywords.append(\"2\")\n",
    "        elif x =='benz':\n",
    "            keywords.append(\"1\")\n",
    "        elif x =='audi':\n",
    "            keywords.append(\"0\")\n",
    "    def model(x):\n",
    "        if x =='corolla':\n",
    "            keywords.append(\"6\")\n",
    "        elif x =='x1':\n",
    "            keywords.append(\"7\")\n",
    "        elif x =='c200':\n",
    "            keywords.append(\"5\") \n",
    "        elif x =='a1':\n",
    "            keywords.append(\"1\")  \n",
    "        elif x =='x3':\n",
    "            keywords.append(\"9\")  \n",
    "        elif x =='x2':\n",
    "            keywords.append(\"2\")\n",
    "        elif x =='allion':\n",
    "            keywords.append(\"0\") \n",
    "        elif x =='c180':\n",
    "            keywords.append(\"3\") \n",
    "        elif x =='a3':\n",
    "            keywords.append(\"8\")\n",
    "        elif x =='yaris':\n",
    "            keywords.append(\"4\")  \n",
    "        elif x =='KDH':\n",
    "            keywords.append(\"10\")    \n",
    "    def color(x):\n",
    "        if x =='black':\n",
    "            keywords.append(\"1\")\n",
    "        elif x =='white':\n",
    "            keywords.append(\"5\")\n",
    "        elif x =='green':\n",
    "            keywords.append(\"3\") \n",
    "        elif x =='ash':\n",
    "            keywords.append(\"0\")  \n",
    "        elif x =='red':\n",
    "            keywords.append(\"2\")  \n",
    "        elif x =='blue':\n",
    "            keywords.append(\"4\")    \n",
    "    def types(x):\n",
    "        if x =='car':\n",
    "            keywords.append(\"0\")\n",
    "        elif x =='suv':\n",
    "            keywords.append(\"1\")\n",
    "        elif x =='van':\n",
    "            keywords.append(\"2\")    \n",
    "    def year(x):\n",
    "        if x =='2007':\n",
    "            keywords.append(\"2007\")\n",
    "        elif x =='2008':\n",
    "            keywords.append(\"2008\")\n",
    "    buySell(split_sentence[i])\n",
    "    condition(split_sentence[i])\n",
    "    brand(split_sentence[i])\n",
    "    model(split_sentence[i])\n",
    "    types(split_sentence[i])\n",
    "    color(split_sentence[i])\n",
    "    year(split_sentence[i])\n",
    "    i+=1\n",
    "print (keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c74f01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "predictions=model.predict(X_test)\n",
    "score=accuracy_score(y_test,predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40017d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=model.predict([keywords])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bd05700",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = label_encoder.inverse_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5a4bf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['buy brandnew toyota corolla car black 2008'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a74913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
